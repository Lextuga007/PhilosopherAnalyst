[
  {
    "path": "posts/2022-06-07-prework-for-courses/",
    "title": "Prework for courses",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Zoë Turner",
        "url": {}
      }
    ],
    "date": "2022-06-07",
    "categories": [],
    "contents": "\r\nNot all NHS sites can access the main training site I use for the\r\nIntroduction to R and R Studio so here are the details for the Prework\r\nwith images in a form that I hope can be viewed by all sites:\r\nSet up RStudio Cloud\r\nSign up for a free RStudio Cloud account at https://rstudio.cloud/\r\nbefore the workshop. Log in with either an existing Google or GitHub\r\naccount, or alternatively set up an account directly with RStudio\r\nCloud.\r\nNHS-R Community will send an email confirmation that will include the\r\nspecific RStudio Cloud workspace invitation link.\r\nAll the files and necessary packages are pre-loaded to the Cloud\r\nworkspace.\r\nWhen you first log in with the link shared in the email it will take\r\nyou to an R Studio Cloud screen that says about Joining a space. Click\r\non the blue button for Join Space:\r\nScreenshot of the workspace view in R\r\nStudio CloudThe next screen that loads is a welcome page to the workshop (note\r\nthat this screenshot is for the Shiny course):\r\nScreenshot of the welcome page after Join\r\nSpace has been selectedThe final screen looks blank as it will say All Projects but nothing\r\nwill be listed. If you click on the blue New Project this will start up\r\nthe project that has all the necessary documents and packages all\r\nloaded. It can still take a few minutes to load:\r\nScreenshot of the Projects page which\r\nwill be emptyIf you want to use\r\nyour own laptop/computer\r\nSome VPNs (Virtual Private Networks) block access to RStudio Cloud or\r\nyou may wish to use your own computer. VPNS sometimes do work but block\r\nparts of the R functionality, this is particularly a problem with Shiny\r\napps (which is not covered in the Introduction to R and R Studio\r\ncourse).\r\nIf that is the case please ensure you have the\r\nlatest R and\r\nRStudio\r\ninstalled.\r\nA screenshot of a broken screen of\r\nsmashed glassIt is important to have the latest R installed as older versions of R\r\nhave had issues when installing tidyverse packages. Errors say that\r\npackages like broom or readr cannot be\r\ninstalled but even when this has been installed separately there\r\ncontinue to be other errors. Some of the answers\r\nin this post from RStudio community may help.\r\nIf you require permission for programs to be installed on your\r\ncomputer and have got an older version of R and R Studio, it is worth\r\nasking for these to be updated by your IT department as this is always\r\ngood practice for fixing known issues and bugs.\r\nPackages\r\nWe will be using the packages {tidyverse} and {rmarkdown}, and whilst\r\nthese packages are all available through CRAN and should be allowed by\r\nmost organisations, if you have strict restrictions on what can be\r\ninstalled please have these approved or it may be better to use RStudio\r\nCloud for the training.\r\ninstall.packages(\"tidyverse\") << This will be\r\ncovered in the course itself\r\ninstall.packages(\"rmarkdown\")\r\nOctober 2021\r\nWith the addition of slides and exercises for working with SQL\r\ndatabases, the following packages will also be required:\r\ninstall.packages(c(\"DBI\", \"dbplyr\"))\r\nIt’s advisable to restart your R session before using any newly\r\ninstalled packages. Use the R Studio menu item Session > Restart\r\nR or the associated keyboard shortcut:\r\nCtrl + Shift + F10 (Windows and Linux) or\r\nCommand + Shift + F10 (Mac OS).\r\nCourse materials\r\nDownloading files\r\nIf you plan to use the RStudio Cloud you can still download the\r\nfollowing files, but it’s not necessary for the workshop.\r\nIf, however, you want to use your own computer go to https://github.com/nhs-r-community/intro_r_data and\r\nclick on the green Code button\r\nScreenshot of the GitHub download files\r\npage with the selection from the dropdown of Download zip\r\nhighlightedThe zip includes the data files which will be used in the workshop. I\r\nhave converted the slides to be published online (see below) and made a\r\nfew updates to refresh the content.\r\nUsing code to download files\r\nIf you want to use code to download all the files, open the zip file\r\nand create a project in R Studio to work from then the following package\r\nand code is needed:\r\ninstall.packages(\"usethis\")\r\nusethis::use_course(\"nhs-r-community/intro_r_data\")\r\nDownloading slides\r\nIf you want to have the slides on your computer, they can be\r\ndownloaded from the same repository as the intro-r files but on a branch\r\ncalled gh-pages.\r\nUsing the same process as for Downloading files above you\r\ncan download these to your computer by clicking on the green button and\r\nselecting the zip download.\r\nConfirmation email\r\nThe NHS-R Community confirmation email will include: the link to the\r\nworkshop, the RStudio Cloud workspace url and you should also receive a\r\ncalendar invitation. If you are not sure that you can access zoom from\r\nyour work laptop, please join a test zoom meeting coordinated by NHS-R\r\nCommunity.\r\nAny problems\r\nPlease contact nhs.rcommunity@nhs.net if you have any issues.\r\nJoin the Slack group\r\nA direct access link to the NHS-R Slack group will be shared in the\r\nworkshop but the settings do allow some email addresses (like nhs.net)\r\nto sign up directly. The Slack url is nhsrcommunity.slack.com.\r\nFeel free to join the Slack group prior to the course!\r\nThere are channels for a wide variety of conversations including #\r\nhelp-with-r and # help-shiny. There is also a channel for # python and #\r\nbook-club.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-12-12T22:50:39+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-03-30-finding-special-characters/",
    "title": "Finding special characters",
    "description": "Notes on getting the ë using shortcut keys on a Windows computer.",
    "author": [
      {
        "name": "Zoë Turner",
        "url": {}
      }
    ],
    "date": "2022-03-30",
    "categories": [
      "Special characters"
    ],
    "contents": "\r\n\r\n\r\n\r\nFigure 1: Photo of a tree from below in the warm Winter light\r\n\r\n\r\n\r\nI recently got a new laptop, an upgrade from the standard NHS Trust\r\nissue, which now means I can open more than one session of RStudio and\r\nhave lots of other Microsoft programs open without the fan going crazy\r\nas it overheats. I should be grateful, and I am, but I’ve spent a long\r\ntime trying to find out how to type my name as there is no numeric\r\nkeypad or shared letter/numbers on the keyboard. It’s not like I don’t\r\ntype my own name much or anything!\r\n\r\nMS Teams - please introduce yourself in the chat: Hello, my name is\r\nZo\r\n\r\nDo I write just a plain e? But that’s not my name. Do I have to go to\r\nanother program or the internet to copy the ë every time I need this?\r\nThat can’t be right can it?!\r\nEven when I think I’ve got my name entered somewhere it gets changed,\r\nlike for this distill post, it came through as ZoÃ« which has a certain\r\nring to it.\r\nUsing Alt for ë\r\nIf I have a keypad I’ve used Alt+0235.\r\nMicrosoft Word has it down as Ctrl+: then the e or\r\nShift+e for a capital but that doesn’t work globally (so not\r\nin MS Teams or RStudio).\r\nAdding a language - doesn’t\r\nwork\r\nI thought adding another language would be a workaround as I added\r\nGerman as, throughout my childhood I’ve always heard people say “ë like\r\nin German”. Only it’s not a German character it seems, it appears in\r\nFrench but no one ever said that. I’ve also heard it said that if you\r\ncut a worm half you get two worms which is complete nonsense so I should\r\nalways question this stuff.\r\nAdding another language like French does give other chacaters but I\r\ngot é where I hoped I’d get ë.\r\nExtended keyboard solution\r\nThe solution turns out to be pretty convoluted but here it is for\r\nfuture me:\r\nWindows button then Language settings\r\nPreferred language is probably already\r\nEnglish (United Kingdom)\r\nClick on the language and then Options\r\nAdd keyboard and scroll down (the list is not in any\r\norder) and select United Kingdom Extended\r\nThe new keyboard appears by the time along the bottom of the\r\nscreen:\r\nScreenshot of the menu of two keyboards\r\nwhich appears next to the timeToggling\r\nbetween the keyboards can be done using Alt+Shift but\r\nthat just shows the menu which you need to then select the language\r\nusing the mouse at least on my computer. I thought I’d just need the\r\nextended keyboard but it seems that when I use the back tick here in\r\nRStudio the extended keyboard only does the ticks if I select it twice\r\nand then I get an extra back tick for my efforts.\r\nGetting the ë\r\nTo get the ë, now this is the fun part.\r\nHold down the alt gr key (to the right of the space bar)\r\nand select the number 2\r\nLet go of both keys and then select e or Ctrl+e for a\r\ncapital\r\nGetting other characters\r\nOccasionally I like to use the é character, particularly for Hugo\r\nApéro and my colleagues surname has a special character ú and to get\r\nthese I hold down the alt gr key with the letter I want.\r\nThis works for the standard keyboard as well as the extended so\r\nthat’s a nice find.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-03-30-finding-special-characters/img/tree-in-winter-light.png",
    "last_modified": "2022-12-12T22:50:38+00:00",
    "input_file": {},
    "preview_width": 2100,
    "preview_height": 2800
  },
  {
    "path": "posts/2021-11-24-losing-the-plots/",
    "title": "Losing the plots",
    "description": "When losing my plotting coding turned into a learning opportunity.",
    "author": [
      {
        "name": "Zoë Turner",
        "url": {}
      }
    ],
    "date": "2021-11-24",
    "categories": [],
    "contents": "\r\nDon’t Panic\r\nI started the day thinking my task would be easy. I had been asked to update a report I’d created a couple of years ago and although I had a week to do it, much longer than such requests can often be, I really wanted to help get this data together quickly. The report had previously been used, I was told, to make a case for better CCTV equipment. That case had been won and now patients and staff had equipment had could provide evidence validate complaints and support prosecutions. Who wouldn’t want to pull out the stops for that kind of feedback!\r\nIncluding code in Rmarkdown\r\nThe day didn’t go as planned. I’d got the old (html) report but I could not remember where I’d saved the coding files. If I’d only known version control when I’d first written it, it would be in the Git/VSTS.\r\nEven without that, I wish I’d known that putting the following into the top YAML:\r\noutput:\r\n  html_document:\r\n    code_download: yes\r\n    \r\nwould produce a little button in the top right hand corner of the report from which anyone, including me importantly, could get the code. Instead, whilst I searched for my code, I also started looking at reproducing the whole document.\r\nFinding SPC charts with signals\r\nThe re-coding wasn’t going so well though. I’d found the data I needed but I couldn’t for the life of me remember how to get just the SPC charts for wards/incidents only with signals as I’d done originally:\r\n\r\n\r\nlibrary(qicharts2)\r\nlibrary(tidyverse)\r\nlibrary(lubridate)\r\n\r\n# data from the qicharts2 package, vignette https://cran.r-project.org/web/packages/qicharts2/vignettes/qicharts2.html#faceting-readmission-rates-by-gender\r\ncabg_by_month_gender <- cabg %>% \r\n  mutate(month = lubridate::floor_date(date, 'month')) %>% \r\n  group_by(month, gender) %>% \r\n  summarise(readmissions = sum(readmission),\r\n            n            = n())\r\n\r\n# create run chart as an object so that the data can be extracte with plot$data\r\nplot <- qic(month, readmissions, n,\r\n    data      = cabg_by_month_gender,\r\n    facets    = ~ gender, \r\n    chart     = 'run',\r\n    y.percent = TRUE,\r\n    title     = 'Readmissions within 30 days (run chart)',\r\n    ylab      = '',\r\n    xlab      = 'Month')\r\n\r\n# keep the data for the category with a signal\r\nplot_signal <- plot$data %>% \r\n  filter(runs.signal == TRUE) %>% \r\n  select(facet1,y.sum, x) %>% \r\n  group_by_(~ facet1) \r\n\r\n# rename back to original column names so that the later chart code doesn't need to change\r\nplot_signal <- rename(plot_signal, \r\n                       'gender' = 'facet1',\r\n                       'start_of_month' = 'x',\r\n                       'total' = 'y.sum')  \r\n\r\n# run charts for only where there is a signal\r\nsignal_plot <- qic(start_of_month, total,\r\n                         data     = plot_signal,\r\n                         facets   = ~ gender,\r\n                         chart    = 'run',\r\n                         #y.percent = TRUE,\r\n                         title    = 'Signal runs',\r\n                         ylab     = '',\r\n                         xlab     = 'Month'\r\n) \r\n\r\n# print chart in rmd\r\nsignal_plot\r\n\r\n\r\n\r\n#print list of what is shown\r\nsignal_plot$data %>% \r\n  select(facet1) %>% \r\n  group_by(facet1) %>% \r\n  slice(1) %>% \r\n  pull(facet1)\r\n\r\n\r\n[1] Female\r\nLevels: Female\r\n\r\nI knew that [@_johnmackintosh](https://twitter.com/_johnmackintosh) had written the original blog that I’d used to do this but it was on a different site to his blog plus he’s build two great packages (runcharter and spccharter) that I really should be using but my panic was rising and I couldn’t really think straight to do anything that constructive!\r\nBut then, suddenly, I just found it.\r\nMicrosoft explorer search of Rmarkdown\r\nStrangely though, I couldn’t find it using Microsoft search, even in the very folder that I knew it was in.\r\nAs I had a complaint to make, of course I turned to Twitter:\r\nImage of tweet saying: “I learned today that MS explorer search is not my friend. It can’t find text from Rmarkdown so I couldn’t find my files. I don’t have these problems with GitHub and yet… Microsoft owns GitHub”and I really should have moaned sooner as I got great responses from people on how and why to resolve this!\r\nSolutions suggested were:\r\n\r\ngrep probably works on Git Bash in Windows I’m guessing?\r\n\r\n[@ChrisBeeley](https://twitter.com/ChrisBeeley) and [@ERDonnachie](https://twitter.com/ERDonnachie) confirmed this does work\r\n\r\nYou probably need to change the indexing options in explorer to include Rmd files. Link\r\n\r\n[@TomJemmett](https://twitter.com/tomjemmett)\r\n\r\nYou can search cloned repositories locally using ‘git-grep’. If you have Linux bash on Win, you can also try ‘grep -r …’ and qualify it however you need (don’t do the entire HDD or it’ll take forever). See the docs. If you don’t have bash, you should Link\r\n\r\n[@Pouriaaa](https://twitter.com/Pouriaaa)\r\nNow I know that I will forget this and I’ll never find it again in Twitter so I’ve got it right here for that future me.\r\nPlus if anyone is reading this blog, do follow these people as they are just the best!\r\nTime on my hands\r\nNow that I had my code it was a ridiculously quick thing to update it to the new data and also change my horrific naming conventions which, quite frankly, were all over the place.\r\nWith that done, I shared the report and got instant feedback:\r\n\r\nThank you for this! I think this report will do the trick Any chance you could do this by individual wards?\r\n\r\nNow, the wards in question numbered just 10, but I had presented the data 4 ways. I’d created functions for the charts but I’d still typed out a title for each ward and then the function code. Doing that 40 times is quite a bit of typing.\r\nAutomatic tabs in Rmarkdown\r\nMy solution was therefore to move from functions that are run individually to running it through a loop, but I also particularly wanted Rmarkdown tabs so that the overall Rmarkdown report isn’t too long. Scrolling down an html page through 40 charts is about as much fun as typing out the titles for them.\r\nAs I do under such circumstances of “is this even possible?” I asked the question of Google and got a Stackoverflow answer. This looked really good but didn’t work for my {qicharts2} charts.\r\nA bit more googling and lo, it appeared to be a problem with the code being base R specific.\r\nA bit of moving code about and I eventually got:\r\n\r\n\r\n# To work correctly in Rmarkdown there must be a header before this chunk with two ##s with ## {.tabset .tabset-fade} after it, for example: ## Cause Group Incidents by Wards {.tabset .tabset-fade}\r\n\r\nfor(i in wards){ \r\n  \r\n  cat(\"###\", i, '<br>', '\\n')\r\n  \r\n  data <- data %>%\r\n    filter(department == i) %>%\r\n    group_by(start_of_month, cause_group) %>%\r\n    summarise(count = n_distinct(incident_number)) %>%\r\n    arrange(start_of_month)\r\n  \r\n  chart <- qic(start_of_month,count,\r\n               data     = data,\r\n               subtitle = 'All incidents',\r\n               chart    = 'run',\r\n               facets   = ~ cause_group,\r\n               title    = paste(\"Run chart for incidents by Cause Group for\", \r\n                                i, sep = \" \"),\r\n               ylab     = 'Number of incidents',\r\n               xlab     = 'Month',\r\n               caption  = 'Only incident number is counted not the number of people affected by an incident')\r\n  \r\n  print(chart)\r\n  \r\n  cat('\\n', '<br>', '\\n\\n')\r\n  \r\n}\r\n\r\n\r\n\r\nThis code won’t run on its own but this one (Code) in the NHS-R Community GitHub Demos and How Tos does.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-11-24-losing-the-plots/losing-the-plots_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2022-12-12T22:50:38+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-05-02-creating-a-caseload-over-time-in-sql/",
    "title": "Creating a caseload over time in SQL",
    "description": "How to count referrals/patients/anything between two dates in a given period of time.",
    "author": [
      {
        "name": "Zoë Turner",
        "url": {}
      }
    ],
    "date": "2021-05-02",
    "categories": [
      "SQL"
    ],
    "contents": "\r\n\r\n\r\n\r\nFigure 1: Photo of pink tulip with frilly ends of petals\r\n\r\n\r\n\r\nI wrote a similar blog, with almost the same title and everything, but with R and now SQL gets its time to shine! I said in the previous blog that I’d spent a long time puzzling over the problem of counts over a period of time, particularly for referrals or caseload; in truth, most of that problem solving was for SQL and the R code was based on the underlying theory.\r\nThe blog referred to these scenarios of open referrals/caseload in a given period:\r\n\r\n1\r\nThe methodology for R was different because I could use specific verbs: complete() and seq.Date() to create the observations/rows between dates but these don’t exist (that I know of) in SQL. To do the same thing in SQL this needs to be done using a JOIN.\r\nCode solution\r\nCreate some data\r\nI’ve coded with SQL for nearly a decade and still struggle with reproducing data in it whereas in R it’s a doddle2 so I exported the R data frame I created and then imported it into SQL. It did mean that I could double check the final counts were the same which was useful!\r\nThe data warehouse that I use has a look up table of dates from 1900 until well into the future, with a single row of observations for each day. Other information is in there like, what was the day of the week, what financial year was it, is it today? But in the absence of such a table you will need to create a table with dates like so3:\r\n\r\n--Create date sequence in SQL using the first start date and the last end date from the data, \r\n--in this case I saved it in the SQL table under my own schema ZT and called the table Data\r\nDECLARE @startDate date = (SELECT MIN(start_date) FROM ZT.Data),\r\n    @endDate date = (SELECT MAX(end_date) FROM ZT.Data);\r\n \r\nSELECT DATEADD(day, number - 1, @startDate) AS [Date]\r\nINTO #calendar\r\nFROM (\r\n    SELECT ROW_NUMBER() OVER (\r\n        ORDER BY n.object_id\r\n        )\r\n    FROM sys.all_objects n\r\n    ) S(number)\r\nWHERE number <= DATEDIFF(day, @startDate, @endDate) + 1;\r\n\r\nFill in the dates between start and end date\r\nAlso adding in the floored dates for month and year4\r\n\r\nSELECT *\r\n,DATEADD(MONTH,DATEDIFF(MONTH,0,date),0) AS month_year\r\n,DATEADD(YEAR,DATEDIFF(YEAR,0,date),0) AS [year]\r\nINTO #extended\r\nFROM ZT.[data]\r\nINNER JOIN #calendar AS cal ON [start_date] <= cal.date AND [end_date] > = cal.date\r\n\r\nCount the observations\r\nTo match the previous counts in R where the individual referrals by patient were counted in a period, in SQL you have to merge the two data together because DISTINCT(patient_id, referral_id) won’t work\r\nBy month and year\r\n\r\nSELECT month_year\r\n,COUNT(DISTINCT CONCAT(patient_id, referral_id))\r\nFROM #extended\r\nGROUP BY month_year\r\nORDER BY month_year\r\n\r\nBy year\r\n\r\nSELECT [year]\r\n,COUNT(DISTINCT CONCAT(patient_id, referral_id))\r\nFROM #extended\r\nGROUP BY [year]\r\nORDER BY [year]\r\n\r\nLooking for a fixed period\r\nIf you only want one period of time and don’t want, or need, to create the calendar lookup counts can be done for ‘being open’ in the WHERE clause5:\r\n\r\nDECLARE @start_period datetime2 = '2020-12-01 00:00:00.0000000'\r\nDECLARE @end_period datetime2 = '2021-12-31 00:00:00.0000000'\r\n\r\nSELECT COUNT(DISTINCT CONCAT(patient_id, referral_id))\r\nFROM ZT.data\r\nWHERE ((end_date >= @start_period) AND [start_date] <= @end_period)\r\n\r\nOr more explicitly:\r\n\r\nDECLARE @start_period datetime2 = '2020-12-01 00:00:00.0000000'\r\nDECLARE @end_period datetime2 = '2021-12-31 00:00:00.0000000'\r\n\r\nSELECT COUNT(DISTINCT CONCAT(patient_id, referral_id))\r\nFROM ZT.data\r\n--Started before period and ended after period or still open (Patient 6)\r\nWHERE (([start_date] < @start_period AND (end_date > = @end_period)) \r\n--Started and ended in period (Patient 3) and (Patient 2)\r\nOR ([start_date] < = @end_period AND end_date > = @start_period) \r\n--Started in period and ended after period or still open (Patient 4)\r\nOR ([start_date]> = @start_period AND (end_date > = @end_period)))\r\n\r\nAny other ways?\r\nThis is possibly something analysts across the NHS have solved so I’d be really interested in hearing about any other ways of creating caseloads or counting open referrals in a given period.\r\n\r\nThe link no longer works but I’ve emailed AphA about the document which was here https://www.aphanalysts.org/wp-content/uploads/2016/08/JOIS_2016_038_Diagnosing_the_Flow_Constraint_i.pdf↩︎\r\nInformal British meaning very easy to do↩︎\r\nFrom a blog by Andrey Zavadskiy↩︎\r\nFrom Stackoverflow↩︎\r\nThe code for this WHERE clause was shared with me from a previous colleague, Barney Lawrence whose blog and Twitter are worth checking out for more SQL information.↩︎\r\n",
    "preview": "posts/2021-05-02-creating-a-caseload-over-time-in-sql/img/pink-tulip.jpg",
    "last_modified": "2022-12-12T22:50:38+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-01-creating-a-caseload-over-time-in-r/",
    "title": "Creating a caseload over time in R",
    "description": "How to count referrals/patients/anything between two dates in a given period of time.",
    "author": [
      {
        "name": "Zoë Turner",
        "url": {}
      }
    ],
    "date": "2021-05-01",
    "categories": [
      "Generate data",
      "R"
    ],
    "contents": "\r\n\r\n\r\n\r\nFigure 1: Photo of dark pink tee blossom\r\n\r\n\r\n\r\nThe puzzle\r\nMy wonderful colleague Lori asked a question on some analysis that I hadn’t really considered for a long time but I had spent an inordinate amount of time solving a few years ago. She wanted to assess caseload1 over time to see if things had changed.\r\nThe logic\r\nThe logic of finding people is summed up nicely here:\r\n\r\n2\r\nIt covers all the scenarios of a particular time period:\r\nWho was open before the period and still open in the period\r\nWho was open and closed in the period\r\nWho was open in the period but closed outside of the period\r\nWho was open before the period and closed after the period\r\nAnd needs to exclude those who are:\r\nOpen and closed before the period\r\nOpen and closed after the period\r\nIf the period of time you are looking for is repeated, so over several years or several months, thoughts may turn to some sort of loop to repeatedly count the people.\r\nStop!\r\nThe secret\r\nIt’s all in the dates. The solution is to create an observation, a row essentially, for every date between the start and end dates. This then offers the flexibility to count by any period.\r\nWord of warning\r\nNote that tables can be huge if you are working with large datasets which cover long periods of time and are creating observations at the day level rather than month or year. Even so, R coped well with a dataset that had 18.5k over several years, ending up as 5,5 million observations. It took about 30 seconds to complete but if you find things are unbearably slow the options are either to increase RAM capacity, use the power of a SQL server, or the other options may be to recode using other packages like data.table.\r\nCode solution\r\nCreate some data\r\n\r\n\r\nlibrary(lubridate)\r\nlibrary(tidyverse)\r\n\r\nset.seed(130) # so the numbers generated will replicate\r\n\r\n# create random start and end dates and ids which can be repeated\r\ndata <- data.frame(\r\n  start_date = sample(seq(as.Date('2019/01/01'), as.Date('2021/01/01'), by = \"day\"), 300),\r\n  end_date = sample(seq(as.Date('2019/01/01'), as.Date('2021/01/01'), by = \"day\"), 300),\r\n  patient_id = floor(runif(300, min = 1, max = 300))\r\n)\r\n\r\n# Add a referral_id which is realistic and also because a patient_id can have multiple dates generated like patient_id 10 for example\r\n\r\ndata_filtered <- data %>% \r\n  filter(end_date > start_date) %>% \r\n  group_by(patient_id) %>% \r\n  mutate(referral_id = row_number(start_date))\r\n\r\n\r\n\r\nFill in the dates between start and end date\r\nThe function that gets all the dates betweeen the start and end date is complete() from the tidyr package (part of tidyverse). In this case the code is creating a sequence using seq.Date and filling in by day. This could be by month or by year but for this example it’s by day as it’s not too big a dataset and gives greater flexibility on the later counts which are by month and then by year.\r\n\r\n\r\n    # Create an observation for every date between the start and end date \r\n    data_expanded <- data_filtered %>%\r\n      group_by(patient_id,\r\n               referral_id) %>% \r\n      pivot_longer(cols = ends_with(\"date\"),\r\n                   names_to = \"caseload\",\r\n                   values_to = \"dates\") %>% \r\n      complete(dates = seq.Date(min(dates), max(dates), by=\"day\")) %>% \r\n      ungroup() # affects any counts or summarising later\r\n\r\n\r\n\r\nCount the observations\r\nBy month and year\r\n\r\n\r\ndata_expanded %>% \r\n  mutate(month_year = lubridate::floor_date(dates, \"1 month\")) %>% \r\n  group_by(month_year) %>% \r\n  summarise(count = n_distinct(patient_id, referral_id))\r\n\r\n\r\n# A tibble: 25 x 2\r\n   month_year count\r\n   <date>     <int>\r\n 1 2019-01-01    14\r\n 2 2019-02-01    25\r\n 3 2019-03-01    38\r\n 4 2019-04-01    48\r\n 5 2019-05-01    57\r\n 6 2019-06-01    68\r\n 7 2019-07-01    75\r\n 8 2019-08-01    78\r\n 9 2019-09-01    80\r\n10 2019-10-01    78\r\n# ... with 15 more rows\r\n\r\nBy year\r\n\r\n\r\ndata_expanded %>% \r\n  mutate(year = lubridate::year(dates)) %>% \r\n  group_by(year) %>% \r\n  summarise(count = n_distinct(patient_id, referral_id))\r\n\r\n\r\n# A tibble: 3 x 2\r\n   year count\r\n  <dbl> <int>\r\n1  2019   120\r\n2  2020   116\r\n3  2021     1\r\n\r\n\r\nalso known as open referrals but this can be anything with a start and end date↩︎\r\nThe link no longer works but I’ve emailed AphA about the document which was here https://www.aphanalysts.org/wp-content/uploads/2016/08/JOIS_2016_038_Diagnosing_the_Flow_Constraint_i.pdf↩︎\r\n",
    "preview": "posts/2021-05-01-creating-a-caseload-over-time-in-r/img/dark-pink-blossom.jpg",
    "last_modified": "2022-12-12T22:50:38+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-13-finding-sql-varcharmax/",
    "title": "Finding SQL varchar(max)",
    "description": "SQL code to find the columns of max that need to be moved to the end of code for importing to R",
    "author": [
      {
        "name": "Zoë Turner",
        "url": {}
      }
    ],
    "date": "2021-02-13",
    "categories": [
      "SQL",
      "Error in R"
    ],
    "contents": "\r\n\r\n\r\n\r\nFigure 1: Photo of tree branches in silohette\r\n\r\n\r\n\r\nImport problems\r\n\r\n\r\n\r\nFigure 2: Tweet: Dates stored as varchar is the SQL equivalent of ‘red pants in the white wash’\r\n\r\n\r\n\r\n@_JohnMackintosh posted in Twitter about his ‘red pants in the wash’ being those date columns that are in fact varchar(). I’ve been very lucky as our data warehouse people have consistently formatted dates in the SQL tables including my favourite integer yyyymmdd format which beautifully imports into R with no issues.\r\nWhat I have found though, which is my ‘red sock in the wash’, is varchar(max) or nvarchar(max) data which, it seems, causes an import error unless these columns are placed at the end of the select script or recoded by using something like CAST(colm AS varchar(150)).\r\nMy sock\r\nThe first time I noticed this, it was because of a table I had built myself. I had put in a column for comments and naturally went for varchar(max). To solve the problem I just changed the data type for the column - because I could.\r\nOthers’ socks\r\nThe next time I encountered this, which wasn’t too long after, it was in a database I couldn’t update so I found my import scripts to R failing with an error:\r\n\r\nError in result_fetch(res@ptr, n) : nanodbc/nanodbc.cpp:3011: 07009: [Microsoft][ODBC SQL Server Driver]Invalid >Descriptor Index Failed to execute SQL chunk\r\n\r\nwhich isn’t really descriptive but searching for the error brought this up for the ODBC package:\r\n\r\n\r\n\r\nFigure 3: GitHub Issue: Short story is this is a bug in the MIcrosoft Driver with varchar(max) columns and they need to be at the end of the select query to work.\r\n\r\n\r\n\r\nFinding the socks\r\nSome of the tables I was working with have nearly 100 columns and whilst I can scan through for them, I’ve recently had to import about 20 tables so this would be long-winded.\r\nFirst, find your data type number:\r\n\r\n\r\n-- USE database_example\r\n\r\nSELECT system_type_id, name\r\nFROM sys.types\r\nWHERE system_type_id = user_type_id\r\n\r\nThen when you know what varchar(max) or even nvarchar(max) is listed under for your own database search for it with this:\r\n\r\n\r\n-- USE database_example\r\n\r\nSELECT\r\n    SchemaName = s.name\r\n    ,o.type_desc\r\n    ,ObjectName = o.name\r\n    ,ColumnName = c.Name\r\nFROM sys.objects AS o\r\nLEFT JOIN sys.schemas AS s ON o.schema_id = s.schema_id\r\nLEFT JOIN sys.all_columns AS c ON o.object_id = c.object_id\r\nWHERE c.system_type_id IN (231, 167)\r\nAND c.max_length = -1\r\n\r\n--Other useful code to restrict what is returned\r\nAND s.name IN ('schema_name') -- restrict to the schema\r\nAND o.type_desc = 'VIEW' -- or USER_TABLE \r\nAND o.name LIKE '%table_name%' -- or use = 'precise_table_name'\r\n\r\nMoving the socks\r\nUnfortunately, now I can’t use the really straight forward script:\r\n\r\n\r\nSELECT *\r\nFROM schema.Table\r\n\r\nand instead I have to list out all 100 columns and move those that are varchar(max) to the end. Still, this code saves lots of peering at the screen.\r\n\r\n\r\n\r\nFigure 4: Happy bouncing blue and white sock\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-02-13-finding-sql-varcharmax/img/tree-branch-silohette.PNG",
    "last_modified": "2022-12-12T22:50:38+00:00",
    "input_file": {},
    "preview_width": 2220,
    "preview_height": 2400
  },
  {
    "path": "posts/2021-02-08-using-monstr-package/",
    "title": "Using the monstR package",
    "description": "Gettting regional deaths from the monstR package",
    "author": [
      {
        "name": "Zoë Turner",
        "url": {}
      }
    ],
    "date": "2021-02-08",
    "categories": [
      "ONS data",
      "R"
    ],
    "contents": "\r\n\r\n\r\n\r\nFigure 1: Photo of snowdrops\r\n\r\n\r\n\r\nMoving away from messy solutions\r\nI’ve been using weekly provisionally recorded deaths from ONS for a number of years and it started off with getting the data directly and copying, by hand (the horror!), the one bit I needed from the East Midlands into a long table which had been started by a colleague. This was the easiest solution at the time but, as this these things often go, the easiest solution quickly becomes the hardest to maintain.\r\nVarious iterations\r\nThe code I’ve used has various iterations with the first being used for the ons_mortality dataset that is included in the {NHSRdatasets} package. The intention was always for it to be a training dataset, not a reporting dataset, so the data only cover 2010 to 2019 and I would top up the data with newly released information from ONS by running the code used to build the {NHSRdatasets} ons_mortality table for weeks as they were released.\r\nI wrote a vignette on how I built the ons_mortality dataset to show the approach I took to building the data. As my coding in R has improved, I’ve since adapted that code to include:\r\nfunctions to clean the data\r\ncode to scrape from the website where the name changes (each week there is a new url)\r\nfunctions to extract all the tabbed sheets from the downloads and\r\nfunctions to load multiple csvs\r\nONS API\r\nThe code was based on the ever-changing weekly urls throughout 2020, and towards the end of January 2021 I realised that I had muddled the data as I was getting 2021 spreadsheets and calling them 2020.\r\nGoing back over this code, with all it’s intricate cleaning code, was a bit daunting so I thought this would be a perfect time to have a go with the Health Foundation ONS API package called (fantastically!) {monstR}.\r\nWhat I discovered\r\nFirst of all I tried this function: ons_available_datasets() and I got a lot of information in the console. The text was overwhelming and I wasn’t sure what I was looking at. I was just about to write an issue question (the contributors are lovely and have labelled a previous issue of mine as a question and answered it) when I had the breakthrough thought of just popping it into an object and lo, it is actually a data frame that I was looking at in the console.\r\n\r\n\r\nlibrary(monstR)\r\n\r\ndf <- ons_available_datasets()\r\n\r\nview(df)\r\n\r\n\r\n\r\nThe next bit was to look for the data I wanted specifically and, luckily for me, the vignette already refers to it: weekly-deaths-region. I wasn’t sure what all the functions/verbs are doing but the notes said a folder is created.\r\n\r\n\r\nmonstr_pipeline_defaults() %>%  # Uses the monstr 'standards' for location and format\r\n  ons_datasets_setup() %>% \r\n  ons_dataset_by_id(\"weekly-deaths-region\") %>%\r\n  ons_download(format=\"csv\") %>%\r\n  monstr_read_file() %>%  \r\n  monstr_clean() %>%\r\n  monstr_write_clean(format=\"all\")\r\n\r\n\r\n\r\nI searched for this folder for ages. The text output doesn’t say exactly where it goes:\r\n\r\nINFO [2021-02-08 21:18:54] Edition not specified, defaulting to latest version INFO [2021-02-08 21:18:54] Retrieving dataset metadata from https://api.beta.ons.gov.uk/v1/datasets/weekly-deaths-region/editions/covid-19/versions/16 INFO [2021-02-08 21:18:55] Downloading data from https://download.beta.ons.gov.uk/downloads/datasets/weekly-deaths-region/editions/covid-19/versions/16.csv INFO [2021-02-08 21:18:55] File created at /data/raw/ons/weekly-deaths-region/covid-19/weekly-deaths-region-v16.csv\r\n\r\n\r\n– Column specification >—————————————————————— cols( V4_1 = col_double(), Data Marking = col_character(), calendar-years = col_double(), Time = col_double(), administrative-geography = col_character(), Geography = col_character(), week-number = col_character(), Week = col_character(), recorded-deaths = col_character(), Deaths = col_character() )\r\nINFO [2021-02-08 21:18:55] Writing csv data to >/data/clean/ons/weekly-deaths-region/covid-19/weekly-deaths-region-v16.csv\r\nINFO [2021-02-08 21:18:55] Writing xlsx data to >/data/clean/ons/weekly-deaths-region/covid-19/weekly-deaths-region-v16.xlsx\r\nINFO [2021-02-08 21:18:55] Writing rds data to >/data/clean/ons/weekly-deaths-region/covid-19/weekly-deaths-region-v16.rds [1] TRUE\r\n\r\nAnd as a search on Windows 10 files takes ages I couldn’t find the folder. After hours (yes, I’m not sure why it took that long either!) I eventually found it by closing down the project and just saving from default R Studio window. From here I got the folder to load:\r\n\r\npathway <- \"C:\\data\\clean\\ons\\weekly-deaths-region\\2010-19\"\r\n\r\nBut when searching for weekly-deaths-region I had found a previous download in a project folder so I’m a bit baffled how it works. I’ve raised an issue on the GitHub to ask for folder pathway to be highlighted or just have the data be loaded as an object rather than saving, which is my preferred option particularly as the files structure is so long: /data/clean/ons/weekly-deaths-region/covid-19/.\r\nLooking at the data\r\nAfter loading the data (I chose the .rds file to load but there also an .xlsx and a .csv) I filtered it to the area I wanted:\r\n\r\n\r\nreadRDS(\"C:/data/clean/ons/weekly-deaths-region/2010-19/weekly-deaths-region-v1.rds\")\r\n\r\nmortality <- `weekly-deaths-region-v1` %>% \r\n  filter(geography == \"East Midlands\")\r\n\r\n\r\n\r\nThe data only has data from 2010 to 2019 (given that’s the file name it’s not surprising but I missed that!) and makes sense as 2020 was when the data output changed to take into account Covid-19 deaths. There are other editions and the issue/question I mentioned before was answered by Emma Vestesson with an extra bit of code specifying editions.\r\n\r\n\r\n# find 'editions'\r\n\r\nons_available_editions(\"weekly-deaths-region\") \r\n\r\n\r\n\r\nPrints to console\r\n2010-19 - what I’d already downloaded\r\ncovid-19 - what I need\r\nThe code to get 2020 and currently added deaths is:\r\n\r\n\r\nmonstr_pipeline_defaults() %>%  # Uses the monstr 'standards' for location and format\r\n  ons_datasets_setup() %>% \r\n  ons_dataset_by_id(\"weekly-deaths-region\", edition = \"covid-19\") %>% #<<\r\n  ons_download(format=\"csv\") %>%\r\n  monstr_read_file() %>%  \r\n  monstr_clean() %>%\r\n  monstr_write_clean(format=\"all\")\r\n\r\n\r\n\r\nUsefully, and perhaps why this is saved to folders rather than loaded as objects, this creates a folder in the same area as the other code: C:/data/ons/weekly-deaths-region/covid-19 and here I get v16 and v17 data.\r\n\r\n\r\nreadRDS(\"C:/data/clean/ons/weekly-deaths-region/covid-19/weekly-deaths-region-v16.rds\")\r\n\r\nreadRDS(\"C:/data/clean/ons/weekly-deaths-region/covid-19/weekly-deaths-region-v17.rds\")\r\n\r\n\r\n\r\nAgain, filtering down to make it easier to see what data I have for the region I’m looking at as “East Midlands” and also the recorded_deaths as “total-registered-deaths” as this data includes “deaths-involving-covid-19-occurrences” which, in this case, I don’t want:\r\n\r\n\r\nmortality_v16 <- `weekly-deaths-region-v16` %>% \r\n  filter(geography == \"East Midlands\",\r\n         recorded_deaths == \"total-registered-deaths\")\r\n  \r\nmortality_v17 <- `weekly-deaths-region-v17` %>% \r\n  filter(geography == \"East Midlands\",\r\n         recorded_deaths == \"total-registered-deaths\")\r\n\r\n\r\n\r\nTwo versions\r\nBoth have 2020 and 2021 data and return the same number of obs. It may be that something has changed in the versions in a different area of the data as when I use the package {dataCompareR} I confirmed this data extraction is exactly the same:\r\n\r\n\r\nlibrary(dataCompareR)\r\n\r\n# This needs a common identifier, which there isn't one in the objects so I've ordered and then added a row_number:\r\n\r\nmortality_v16 <- `weekly-deaths-region-v16` %>% \r\n  filter(geography == \"East Midlands\",\r\n         recorded_deaths == \"total-registered-deaths\") %>% \r\n  arrange(week_number,\r\n          calendar_years) %>% \r\n  mutate(rn = row_number())\r\n  \r\nmortality_v17 <- `weekly-deaths-region-v17` %>% \r\n  filter(geography == \"East Midlands\",\r\n         recorded_deaths == \"total-registered-deaths\") %>% \r\n  arrange(week_number,\r\n          calendar_years) %>% \r\n  mutate(rn = row_number())\r\n\r\n# dataCompareR code\r\n\r\nCompared <- rCompare(mortality_v16, mortality_v17, key = \"rn\")\r\n\r\n# I like to save this because I still have to get my head around using lists and this function saves and opens an html at the same time\r\n\r\nsaveReport(Compared, reportName = \"comparing\")\r\n\r\n\r\n\r\nIt makes sense to use the latest version, just in case, and so I need to add the 2010-2019 data for recorded_deaths to the 2020-2021 v17 data:\r\n\r\n\r\n# code copied from earlier chunks to explain the process so it's all in one area\r\n\r\nmortality_v1 <- `weekly-deaths-region-v1` %>% \r\n  filter(geography == \"East Midlands\")\r\n\r\nmortality_v17 <- `weekly-deaths-region-v17` %>% \r\n  filter(geography == \"East Midlands\",\r\n         recorded_deaths == \"total-registered-deaths\",\r\n         !is.na(v4_1)) # not all dates have counts just like the website spreadsheets\r\n\r\nmortality_all_years <- mortality_v1 %>% \r\n  rbind(mortality_v17)\r\n\r\n\r\n\r\nInterestingly, at the time of writing the latest date was week 1 of 2021 but I am writing in week 4 so there appears to be a delay in this data.\r\nThe value of APIs\r\nAPIs are a great way of getting data as it’s from the source and can be updated according to any changes that source holder makes. The difficulty with them is they have their own technological language but R packages are a nice way around that if you are familiar with R.\r\nI think the package looks very promising and could do with more vignettes as I’m pretty sure I wouldn’t have got this far with it if I were very early on in using R. Saying that, contribution is really easy as the Health Foundation team are great at paving the way for open source working.\r\nOther links\r\nThe weekly provisional deaths are published here also monthly deaths at a lower regional level is available here. These are not provisional deaths so can be useful for more accurate tracking but the format of the spreadsheets has changed considerably over time. This was my attempt at tidying it.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-02-08-using-monstr-package/img/snowdrops.jpg",
    "last_modified": "2022-12-12T22:50:38+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-05-creating-sample-datetime-data-in-r/",
    "title": "Creating sample datetime data in R",
    "description": "How to produce a reproducible example (reprex) for datetime",
    "author": [
      {
        "name": "Zoë Turner",
        "url": {}
      }
    ],
    "date": "2021-02-05",
    "categories": [
      "R",
      "Generate data"
    ],
    "contents": "\r\n\r\n\r\n\r\nFigure 1: Frosty leaves\r\n\r\n\r\n\r\nThe product of my drifting mind\r\nI was writing a blog for my team’s blog about working in the open and midway I drifted into writing code. For some reason I had a burning desire to highlight a common issue in SQL with the use of BETWEEN for dates and then ended up spending working out how to create fake date/time data in R.\r\nReading through my team blog I realised it didn’t make sense to have the R data creation code in it so I’ve promoted it to its own blog - this! The SQL thing with BETWEEN will also get its own blog in due course.\r\nReproducible examples\r\nI like producing reprexes1 and I have a few gists where I’ve answered some questions from places like Stackoverflow and R Studio Community by first creating reprexes. These were questions which were removed, unfortunately, before I had a chance to send the reply. One time I had an answer, with a reprex, in just 20 minutes and was about to post, but it had been deleted! I wasn’t prepared to lose that code so I posted it in my own GitHub gist and I’ve used the reprex code many times since.\r\nReproducing what?\r\nI was trying to recreate the SQL date time format YYYY-MM-DD hh:mm:ss[.nnn] that I have in my work’s data warehouse. For this example I’ve only reproduced a random sample in the SmallDateTime YYYY-MM-DD hh:mm:ss format.\r\nLosing the code\r\nI spent a long time trying to work out how to randomly sample the constituent parts of a date time (including hours, minutes and seconds), even using base R code and the chron package to get hm (but not s)2.\r\nBy the end of the day I was very tired and I did a terrible thing: I cut the code from an Untitled and unsaved file, moved to another R project and then copied something else. I didn’t stop there. Oh no, I then copied and pasted several things then, when I finally went to paste what I’d cut originally it was, of course, gone.\r\n\r\n\r\n\r\nWindows history clipboard\r\nTurns out Windows 10 has a clipboard history but you have to switch it on by going to Windows settings/Clipboard settings and switch on history.\r\nI looked for a GIPHY for “nice to know” but none conveyed the right level of sarcasm for that phrase.\r\nEvery cloud has a silver lining and all that…\r\nFrantically re-writing code after deleting huge swathes means that you do get an opportunity to improve the code. At least, that’s what I told myself. And so I re-wrote what I could remember and realised I’d missed the seconds and also how I’d not even checked the {lubridate} package which does indeed produce sequential dates and time which can be sampled:\r\n\r\n\r\nlibrary(lubridate)\r\n\r\nlubridate_dhms <- data.frame(\r\n  hms = sample(seq(ymd_hms(\"2020-1-1 0:00:00\"), ymd_hms(\"2021-1-1 0:00:00\"), \r\n                    by = \"hour\"), 15)\r\n)\r\n\r\n\r\n\r\nBut the by = \"\" only accepts hour, not minute or second so those are all 00:00.\r\nHelp!!!!\r\nBy this point I was a bit fed up so I did what all good coders who have exploited the internet for help do - I asked my NHS-R Community colleagues on Slack:\r\n\r\nIs there any way to generate random hours, minutes and seconds for made-up data?\r\n\r\nAnd I included examples of what I’d attempted.\r\nThus ensued a great thread with my boss, Chris Beeley, who answered the question within minutes.\r\n\r\n\r\nbase_r_dhms <- data.frame(\r\n  sample(seq(as.POSIXlt(\"2020-10-01\"),\r\n      as.POSIXlt(\"2020-10-10\"), by = 1), 15)\r\n)\r\n\r\n\r\n\r\nI asked what the by = 1 means and Chris confirmed this was a 1 second interval so the seq(…) creates the sequence at 1 seconds and then the sample() takes, in this case, 15 data points from this sequence.\r\nIt’s also possible to write “s” or “sec” in place of the 1:\r\n\r\n\r\nbase_r_dhms_same <- data.frame(\r\n  sample(seq(as.POSIXlt(\"2020-10-01\"),\r\n      as.POSIXlt(\"2020-10-10\"), by = \"s\"), 15)\r\n)\r\n\r\n# or\r\n\r\nbase_r_dhms_same <- data.frame(\r\n  sample(seq(as.POSIXlt(\"2020-10-01\"),\r\n      as.POSIXlt(\"2020-10-10\"), by = \"sec\"), 15)\r\n)\r\n\r\n\r\n\r\nBecause I’d also asked about {lubridate} generating random minutes and seconds, and Chris was having too much fun with this he answered that too:\r\n\r\n\r\n# using the code I shared that generates random dates and hours\r\n\r\nhour_min_sec <- data.frame(\r\n  hms = seq(ymd_hms(\"2020-1-1 0:00:00\"), ymd_hms(\"2021-1-1 0:00:00\"), \r\n                    by = \"hour\")\r\n)\r\n\r\n# updating the data frame with random seconds and updating the data\r\nlubridate::second(hour_min_sec$hms) <- sample(0 : 59, nrow(hour_min_sec), replace = TRUE)\r\n\r\n# updating the data frame with random minutes and updating the data\r\nlubridate::minute(hour_min_sec$hms) <- sample(0 : 59, nrow(hour_min_sec), replace = TRUE)\r\n\r\n\r\n\r\nHappy ending\r\nIn response to my saying:\r\n\r\nYou won’t believe how long I’ve been working on this and how many lines of code I have written!\r\n\r\nChris said:\r\n\r\nI bet you learned a lot though\r\n\r\nAnd it’s true.\r\n\r\nReproducible example or data that has been copied or made up to help explain a problem in data↩︎\r\nI used this blog http://datacornering.com/how-to-generate-time-intervals-or-date-sequence-in-r/↩︎\r\n",
    "preview": "posts/2021-02-05-creating-sample-datetime-data-in-r/img/leaves-frost.png",
    "last_modified": "2022-12-12T22:50:38+00:00",
    "input_file": {},
    "preview_width": 2997,
    "preview_height": 3808
  },
  {
    "path": "posts/2021-01-31-adding-disqus-to-distill-blogs/",
    "title": "Adding Disqus to distill blogs",
    "description": "Notes on adding comments to distill pages.",
    "author": [
      {
        "name": "Zoë Turner",
        "url": {}
      }
    ],
    "date": "2021-01-31",
    "categories": [
      "Distill"
    ],
    "contents": "\r\n\r\n\r\n\r\nFigure 1: Photo of frost on wood\r\n\r\n\r\n\r\nInspiration\r\nWhen searching for “distill blog doesn’t show xaringan slides” I stumbled across this blog by Shamindra Shrotriya where I found that it’s possible to add comments to the distill pages.\r\nIssues with images\r\nI’ve never used Disqus before but I followed Shamindra’s blog instructions and it worked. The only thing to note is that images must be in PNG format. Thankfully I’d only included a few so I could convert them by opening them in Microsoft Paint and saving them as .PNG.\r\nI saved as .PNG rather than .png as @tomjemmett had had to set my files to this in the NHS-R Community GitHub to get the xaringan slides there to render. I thought it best to follow this as good practice.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-01-31-adding-disqus-to-distill-blogs/img/frost-on-wood.png",
    "last_modified": "2022-12-12T22:50:38+00:00",
    "input_file": {},
    "preview_width": 4000,
    "preview_height": 3000
  },
  {
    "path": "posts/2021-01-15-data-ethics/",
    "title": "Data Ethics",
    "description": "Philosophers are experts in their field",
    "author": [
      {
        "name": "Zoë Turner",
        "url": {}
      }
    ],
    "date": "2021-01-15",
    "categories": [
      "Philosophy",
      "Ethics"
    ],
    "contents": "\r\n\r\n\r\n\r\nFigure 1: Photo of holly\r\n\r\n\r\n\r\nThis is now published on my Hugo blog site as I’ve decided to keep the {distill} site for technical blogs\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-01-15-data-ethics/img/holly.PNG",
    "last_modified": "2022-12-12T22:50:38+00:00",
    "input_file": {},
    "preview_width": 3968,
    "preview_height": 1984
  },
  {
    "path": "posts/2020-12-19-publishing-xaringan-slides/",
    "title": "Publishing xaringan slides",
    "description": "Notes on how I published my NHS-R Conference lightning talk",
    "author": [
      {
        "name": "Zoë Turner",
        "url": {}
      }
    ],
    "date": "2020-12-19",
    "categories": [
      "Xaringan",
      "GitHub"
    ],
    "contents": "\r\n\r\n\r\n\r\nFigure 1: Chafffinch at bird tables\r\n\r\n\r\n\r\nPublishing xaringan slides\r\nThis is my first attempt to publish my NHS-R Community 2020 Virtual Conference Lightning talk slides using the code shared by Dr. Silvia Canelón who ran the workshop Sharing Your Work with xaringan. I’m indebted to Silvia’s workshop and also to the code she used to publish the workshop slides.\r\n\r\n\r\n\r\nUnfortunately, it looks like they render better on the index.Rmd file and not on an article. The slides look the same (with lost formats and no interactivity) whether the link is to the self-contained html in a repository on my computer or to the url.\r\n\r\n\r\n\r\n\r\n\r\nThis RStudio Community conversation helped me realise this is probably something in distill and not something I was doing. In particular, it’s where @Apreshill says:\r\n\r\nBut also, this is the index.Rmd, not a post, so not entirely sure. I also added this line to my _site.yml, but confess to not testing whether that is required or not for this to work:\r\n\r\nI tried adding the line include: [“slides/”] @Apreshill refers to but that didn’t solve the formatting.\r\nWhy do I need to learn R when I can use SQL?  time: 1:05:07\r\nThings to note when publishing using GitHub\r\nTo get started there are lots of blogs on publishing to GitHub pages but this from R Studio/distill creators is also very clear.\r\nThe following are notes I’ve made and learned around publishing html and xaringan slides to GitHub.\r\nPublishing subfolders\r\nAlthough I managed to publish a GitHub repository following the instructions, I remained frustratingly confused about how to publish the html slides in subfolders. It turned out it was a simple thing that no one mentioned; you just need to add the subfolder directory to the url!\r\nFor example, @tomjemmett had published the NHS-R Community repository https://github.com/nhs-r-community/Conference_2020 and the url becomes: https://nhs-r-community.github.io/Conference_2020/\r\nTo see my xaringan slides I needed to get the page to the subfolder /Lightning_talks/ZoëTurner_SQLvR/ and this only needs to be added to the url like so:  https://nhs-r-community.github.io/Conference_2020/Lightning_talks/Zo%C3%ABTurner_SQLvR/index.html#1\r\nThe #1 at the end of the url refers to the slide number so you can go straight to a particular slide if you want.\r\nIt took me days of looking at websites on how to publish GitHub pages to realise this small thing and the danger of continued searching was that some pages referred to the old way of publishing GitHub pages which necessitated creating a new branch called gh-pages.\r\nThankfully, after days of puzzling over this I decided to take a copy (fork) of Silvia’s repository and run her code, which worked perfectly, so I knew I was on the right lines. Comparing the urls to the slides and where she she had saved them in her repository, I noticed the file paths were the same and then it all clicked for me. The point to all this is that it’s a generous thing to open up your code to such naive scrutiny and I am forever grateful to those that do.\r\nThings to note\r\nI have a special character in my name: Zoë. The ë appears like that in the url but when copied and pasted here, for example, it comes out as Zo%C3%AB. Thankfully, both work, which is good to know if you have an unusual character in your name!\r\nBe patient\r\nI quite often got a 404 error page just after saving a file to publish which was odd as everything worked ok. This was because it can take quite a few minutes for things to refresh.\r\nXaringan slides are blank\r\nAlso note that if the xaringan slides don’t appear but there is a blank box in the top left hand side of the screen and with a slider, it has worked. This can occur if you work on a VPN, as I do, where the security is very tight.\r\nI also noticed the same box when I knitted xaringan slides and I was using a link to a video. The particular slide would only work when the slides were opened in the Chrome browser. Given that the NHS often default to Explorer or Edge browsers, it might also be worth checking you are using Chrome if you are not on a VPN and still get the blank slider box.\r\nXaringan slides are not self-contained\r\nUnlike using html, the xaringan slides need to have the images, CSS and libraries available to run it. I made the mistake of using two folders for my images but it worked out that I used /img for the slide backgrounds and the /images for the pictures related only to that presentation.\r\nUpdate…\r\nSilvia kindly shared the update about making the xaringan presentations ‘self-contained’. I’d used that line of code for this blog originally as I hadn’t read the instructions and had wondered if that was why the slide navigation was missing (see the answer to that below!). Testing how ‘self-contained’ self-contained is I emailed myself just the html and got the text but no formats. Zipping together the html along with the css, img and libs (my names for these) folders did mean the html opened up ok with all the formatting. It’s a little like when saving a webpage and a same-named folder appears that is needed for the html to open.\r\nReasons not to use pdfs\r\nUsing pdfs gets around the need to email out supporting files and folders as it’s just one file to send, however, I’m reluctant to use pdfs because of accessibility as much as aesthetics:\r\nhttps://www.gov.uk/guidance/publishing-accessible-documents\r\n\r\nThink about format\r\nDoing this will help your document support as many users as possible and can future-proof your information.\r\nPublish in HTML format wherever possible so that your documents use your users’ custom browser settings. It can be difficult to make other formats easier to read.\r\nFor example, PDF documents:\r\ncan make your content harder to find, use and maintain do not work well with assistive technologies like screen readers a lot of the time. If your documents do not meet accessibility standards you could be breaking the Equality Act 2010.\r\n\r\nAesthetically, you lose interactivity (dygraphs or plotly charts) or movement in your slides (videos or GIFs) with pdfs so if you look through the commits in my Presentation repository you will see me flicking between html to pdf and back to html as I’ve tried this out.\r\nMissing slide navigation\r\nI was puzzled for a long time why I had published my slides in this blog but the slide navigation was missing. As I consistently fail to read instructions it turned out I needed the line:\r\n\r\n\r\nxaringanExtra::use_share_again()\r\n\r\n\r\n\r\nin the presentation slide code. I put this in the code chunk related to libraries (often listed as r libs).\r\nBecause I missed doing this from the beginning there were a few steps I needed to to to get this to publish on the blog. These were:\r\nPresentation repo\r\nAdd the line of code to the presentation code\r\nKnit the presentation\r\nCommit and push the presentation rmd and html file\r\nBlog repo\r\nKnit the blog post\r\nBuild the website\r\nCommit and push all changes\r\nDo a little celebration jig and thank Silvia yet again for helping me out as she let me know this missing line of code in the NHS-R Community Slack Group\r\n\r\n\r\n\r\n",
    "preview": "posts/2020-12-19-publishing-xaringan-slides/distill-preview.png",
    "last_modified": "2022-12-12T22:50:38+00:00",
    "input_file": {},
    "preview_width": 453,
    "preview_height": 551
  }
]
